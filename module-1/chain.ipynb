{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbf2458",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/chain.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238466-lesson-4-chain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a simple graph with nodes, normal edges, and conditional edges.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's build up to a simple chain that combines 4 [concepts](https://python.langchain.com/v0.2/docs/concepts/):\n",
    "\n",
    "* Using [chat messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as our graph state\n",
    "* Using [chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) in graph nodes\n",
    "* [Binding tools](https://python.langchain.com/v0.2/docs/concepts/#tools) to our chat model\n",
    "* [Executing tool calls](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) in graph nodes \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a55e2e80-a718-4aaf-99b9-371157b34a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "Chat models can use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages), which capture different roles within a conversation. \n",
    "\n",
    "LangChain supports various message types, including `HumanMessage`, `AIMessage`, `SystemMessage`, and `ToolMessage`. \n",
    "\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call. \n",
    "\n",
    "Let's create a list of messages. \n",
    "\n",
    "Each message can be supplied with a few things:\n",
    "\n",
    "* `content` - content of the message\n",
    "* `name` - optionally, a message author \n",
    "* `response_metadata` - optionally, a dict of metadata (e.g., often populated by model provider for `AIMessages`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\", name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about?\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "[Chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) can use a sequence of message as input and support message types, as discussed above.\n",
    "\n",
    "There are [many](https://python.langchain.com/v0.2/docs/concepts/#chat-models) to choose from! Let's work with OpenAI. \n",
    "\n",
    "Let's check that your `OPENAI_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2652d5ec-7602-4220-bc6e-b90783ab287b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os, getpass\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
   "metadata": {},
   "source": [
    "We can load a chat model and invoke it with out list of messages.\n",
    "\n",
    "We can see that the result is an `AIMessage` with specific `response_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "_ = load_dotenv(dotenv_path=\"./studio/.env\")\n",
    "\n",
    "if False:\n",
    "    # OpenAI model\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "else:\n",
    "    # Llama model from Ollama\n",
    "    llm = ChatOllama(\n",
    "        model=\"llama3.2:1b\",\n",
    "        temperature=0.001\n",
    "    )\n",
    "\n",
    "result = llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Orcas, also known as killer whales, are a popular sight among whale watching enthusiasts. In the United States, there are several locations where you can spot them in their natural habitat.\\n\\nHere are some of the top places to see orcas in the US:\\n\\n1. **Puget Sound, Washington**: This is one of the best places in the US to see orcas, particularly in the Puget Sound region around Seattle and Tacoma.\\n2. **San Juan Islands, Washington**: The San Juan Islands are a popular spot for orca sightings, especially during the summer months when they congregate in the waters around the islands.\\n3. **Alaska's Inside Passage**: Alaska is home to a large population of orcas, and the Inside Passage is a great place to see them. You can take a guided tour or go on your own with a boat tour operator.\\n4. **California's Monterey Bay**: The Monterey Bay National Marine Sanctuary is a protected area where you can spot orcas in their natural habitat.\\n5. **Hawaii's Humpback Whale Season (December to May)**: While not exclusively an orca sighting, humpback whales are often seen with orcas in Hawaiian waters during the winter months.\\n\\nSome popular tour operators that offer orca-watching tours in these locations include:\\n\\n* **Orca Watch**: Based in Seattle, Washington\\n* **San Juan Island Tours**: Based in Friday Harbor, Washington\\n* **Alaska Whale Watching**: Based in Seward, Alaska\\n* **Monterey Bay Whale Watch**: Based in Monterey, California\\n\\nKeep in mind that orca sightings can never be guaranteed, as they are wild animals and their behavior is unpredictable. However, these locations offer some of the best chances to see them.\\n\\nAre you planning a specific trip or just interested in learning more about orcas?\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2024-12-02T16:20:51.298724356Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2788493612, 'load_duration': 19429313, 'prompt_eval_count': 81, 'prompt_eval_duration': 2000000, 'eval_count': 373, 'eval_duration': 2765000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-c9159dad-699d-44bf-aeec-8b53ecb3744e-0', usage_metadata={'input_tokens': 81, 'output_tokens': 373, 'total_tokens': 454})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e637aa14",
   "metadata": {},
   "source": [
    "gpt-4o answer:<br>\n",
    "\n",
    "```python\n",
    "AIMessage(\n",
    "    content=\"The best place to see orcas (also known as killer whales) in the United States is typically considered to be the Pacific Northwest, particularly the waters around Washington State. Here are a few specific locations that are well-known for orca sightings:\\n\\n1. **San Juan Islands, Washington**: This is one of the most famous spots for whale watching in the U.S. The islands are located in the Salish Sea, and the area is home to both resident and transient orca pods. You can take a whale-watching tour from Friday Harbor or other nearby locations.\\n\\n2. **Puget Sound, Washington**: Orcas can also be seen in the broader Puget Sound area. There are several whale-watching tours operating from cities like Seattle and Port Townsend.\\n\\n3. **Olympic Coast, Washington**: The Olympic National Park area offers opportunities to view orcas from the shore or by boat. The Strait of Juan de Fuca, which separates Washington State from Vancouver Island, is another good spot.\\n\\n4. **Bellingham and Anacortes, Washington**: These towns are gateways to the San Juan Islands and offer numerous whale-watching tours.\\n\\nThe best time to see orcas in these areas is typically from late spring through early fall, though they can be spotted year-round. It's always a good idea to check with local tour operators for the most current information on whale sightings.\",\n",
    "    additional_kwargs={\"refusal\": None},\n",
    "    response_metadata={\n",
    "        \"token_usage\": {\n",
    "            \"completion_tokens\": 282,\n",
    "            \"prompt_tokens\": 67,\n",
    "            \"total_tokens\": 349,\n",
    "            \"completion_tokens_details\": {\n",
    "                \"accepted_prediction_tokens\": 0,\n",
    "                \"audio_tokens\": 0,\n",
    "                \"reasoning_tokens\": 0,\n",
    "                \"rejected_prediction_tokens\": 0,\n",
    "            },\n",
    "            \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0},\n",
    "        },\n",
    "        \"model_name\": \"gpt-4o-2024-08-06\",\n",
    "        \"system_fingerprint\": \"fp_831e067d82\",\n",
    "        \"finish_reason\": \"stop\",\n",
    "        \"logprobs\": None,\n",
    "    },\n",
    "    id=\"run-f8a03a78-edb9-44ac-a917-61bc3c2979c0-0\",\n",
    "    usage_metadata={\n",
    "        \"input_tokens\": 67,\n",
    "        \"output_tokens\": 282,\n",
    "        \"total_tokens\": 349,\n",
    "        \"input_token_details\": {\"audio\": 0, \"cache_read\": 0},\n",
    "        \"output_token_details\": {\"audio\": 0, \"reasoning\": 0},\n",
    "    },\n",
    ")\n",
    "```\n",
    "\n",
    "<br>llama3.2:1b (local) answer:\n",
    "```python\n",
    "AIMessage(\n",
    "    content=\"Orcas, also known as killer whales, are found throughout the world's oceans, but some areas are particularly known for their high concentration of these magnificent creatures.\\n\\nIn the United States, there are several locations that are considered prime spots to see orcas. Here are a few recommendations:\\n\\n1. **Alaska**: Alaska is one of the best places in the US to spot orcas, particularly in the Inside Passage and around Prince William Sound. The state's diverse marine ecosystem supports a healthy population of orcas.\\n2. **Hawaii**: Humpback whales migrate to Hawaii's waters from December to May, and orcas are also present in Hawaiian waters during this time. You can take a guided tour or visit popular spots like Molokini Crater and Kailua-Kona.\\n3. **California**: The Pacific Ocean off the coast of California is home to orca pods that feed on fish and squid. Some popular locations include Monterey Bay, Big Sur, and Santa Barbara.\\n4. **Oregon**: Oregon's coastal waters are a great place to spot orcas, particularly around Cannon Beach and Ecola State Park.\\n\\nSome specific parks and wildlife refuges in these areas offer guided tours or boat excursions that can increase your chances of spotting orcas:\\n\\n* Alaska: Katmai National Park and Preserve, Kenai Fjords National Park\\n* Hawaii: Humpback Whale National Marine Sanctuary, Maui, Molokini Crater\\n* California: Monterey Bay Aquarium, Santa Cruz Harbor\\n* Oregon: Cannon Beach, Ecola State Park\\n\\nKeep in mind that orca sightings can never be guaranteed, as they are wild animals and their habitats are constantly changing. However, visiting these locations during peak orca migration times (e.g., winter months) increases your chances of spotting them.\\n\\nWhat type of experience are you looking for when it comes to seeing orcas? Are you interested in guided tours, boat excursions, or just learning more about these magnificent creatures?\",\n",
    "    additional_kwargs={},\n",
    "    response_metadata={\n",
    "        \"model\": \"llama3.2:1b\",\n",
    "        \"created_at\": \"2024-11-29T15:53:59.826737768Z\",\n",
    "        \"done\": True,\n",
    "        \"done_reason\": \"stop\",\n",
    "        \"total_duration\": 3028689556,\n",
    "        \"load_duration\": 15750825,\n",
    "        \"prompt_eval_count\": 81,\n",
    "        \"prompt_eval_duration\": 11000000,\n",
    "        \"eval_count\": 400,\n",
    "        \"eval_duration\": 3000000000,\n",
    "        \"message\": Message(role=\"assistant\", content=\"\", images=None, tool_calls=None),\n",
    "    },\n",
    "    id=\"run-3051e3ac-0e10-41e3-ad3b-3dc87525ff21-0\",\n",
    "        usage_metadata={\n",
    "        \"input_tokens\": 81,\n",
    "        \"output_tokens\": 400,\n",
    "        \"total_tokens\": 481\n",
    "    },\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3555b0",
   "metadata": {},
   "source": [
    "[llama 3.2:1b] result.response_metadata:<br>\n",
    "```js\n",
    "{'model': 'llama3.2:1b',\n",
    " 'created_at': '2024-11-29T16:00:29.107766376Z',\n",
    " 'done': True,\n",
    " 'done_reason': 'stop',\n",
    " 'total_duration': 3246664592,\n",
    " 'load_duration': 15115879,\n",
    " 'prompt_eval_count': 81,\n",
    " 'prompt_eval_duration': 10000000,\n",
    " 'eval_count': 362,\n",
    " 'eval_duration': 2752000000,\n",
    " 'message': Message(role='assistant', content='', images=None, tool_calls=None)}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.2:1b',\n",
       " 'created_at': '2024-12-02T16:20:51.298724356Z',\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'total_duration': 2788493612,\n",
       " 'load_duration': 19429313,\n",
       " 'prompt_eval_count': 81,\n",
       " 'prompt_eval_duration': 2000000,\n",
       " 'eval_count': 373,\n",
       " 'eval_duration': 2765000000,\n",
       " 'message': Message(role='assistant', content='', images=None, tool_calls=None)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata  # gpt-4o"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "\n",
    "External systems (e.g., APIs) often require a particular input schema or payload, rather than natural language. \n",
    "\n",
    "When we bind an API, for example, as a tool we given the model awareness of the required input schema.\n",
    "\n",
    "The model will choose to call a tool based upon the natural language input from the user. \n",
    "\n",
    "And, it will return an output that adheres to the tool's schema. \n",
    "\n",
    "[Many LLM providers support tool calling](https://python.langchain.com/v0.1/docs/integrations/chat/) and [tool calling interface](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/) in LangChain is simple. \n",
    " \n",
    "You can simply pass any Python `function` into `ChatModel.bind_tools(function)`.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a942b1",
   "metadata": {},
   "source": [
    "Let's showcase a simple example of tool calling!\n",
    " \n",
    "The `multiply` function is our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f9dba",
   "metadata": {},
   "source": [
    "If we pass an input - e.g., `\"What is 2 multiplied by 3\"` - we see a tool call returned. \n",
    "\n",
    "The tool call has specific arguments that match the input schema of our function along with the name of the function to call.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2024-12-02T16:20:51.588678235Z', 'done': True, 'done_reason': 'stop', 'total_duration': 234638591, 'load_duration': 30318194, 'prompt_eval_count': 172, 'prompt_eval_duration': 7000000, 'eval_count': 26, 'eval_duration': 195000000, 'message': Message(role='assistant', content='', images=None, tool_calls=[ToolCall(function=Function(name='multiply', arguments={'a': '2', 'b': '3'}))])}, id='run-98d46afc-9d37-4e21-a781-de95933c8aff-0', tool_calls=[{'name': 'multiply', 'args': {'a': '2', 'b': '3'}, 'id': '9ebd741c-8e49-476a-9f99-e52251dd70ca', 'type': 'tool_call'}], usage_metadata={'input_tokens': 172, 'output_tokens': 26, 'total_tokens': 198})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"Lance\")])\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe34734",
   "metadata": {},
   "source": [
    "gpt-4o `tool_call`: <br>\n",
    "\n",
    "```python\n",
    "AIMessage(\n",
    "    content=\"\",\n",
    "    additional_kwargs={\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"id\": \"call_SMEH2M5fgqSqYKmTHMhPRj27\",\n",
    "                \"function\": {\"arguments\": '{\"a\":2,\"b\":3}', \"name\": \"multiply\"},\n",
    "                \"type\": \"function\",\n",
    "            }\n",
    "        ],\n",
    "        \"refusal\": None,\n",
    "    },\n",
    "    response_metadata={\n",
    "        \"token_usage\": {\n",
    "            \"completion_tokens\": 17,\n",
    "            \"prompt_tokens\": 62,\n",
    "            \"total_tokens\": 79,\n",
    "            \"completion_tokens_details\": {\n",
    "                \"accepted_prediction_tokens\": 0,\n",
    "                \"audio_tokens\": 0,\n",
    "                \"reasoning_tokens\": 0,\n",
    "                \"rejected_prediction_tokens\": 0,\n",
    "            },\n",
    "            \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0},\n",
    "        },\n",
    "        \"model_name\": \"gpt-4o-2024-08-06\",\n",
    "        \"system_fingerprint\": \"fp_7f6be3efb0\",\n",
    "        \"finish_reason\": \"tool_calls\",\n",
    "        \"logprobs\": None,\n",
    "    },\n",
    "    id=\"run-0e49cdb7-2e36-477b-b00f-8025ad9a6815-0\",\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"name\": \"multiply\",\n",
    "            \"args\": {\"a\": 2, \"b\": 3},\n",
    "            \"id\": \"call_SMEH2M5fgqSqYKmTHMhPRj27\",\n",
    "            \"type\": \"tool_call\",\n",
    "        }\n",
    "    ],\n",
    "    usage_metadata={\n",
    "        \"input_tokens\": 62,\n",
    "        \"output_tokens\": 17,\n",
    "        \"total_tokens\": 79,\n",
    "        \"input_token_details\": {\"audio\": 0, \"cache_read\": 0},\n",
    "        \"output_token_details\": {\"audio\": 0, \"reasoning\": 0},\n",
    "    },\n",
    ")\n",
    "```\n",
    "\n",
    "llama3.2:1b `tool_call`: <br>\n",
    "```python\n",
    "AIMessage(\n",
    "    content=\"\",\n",
    "    additional_kwargs={},\n",
    "    response_metadata={\n",
    "        \"model\": \"llama3.2: 1b\",\n",
    "        \"created_at\": \"2024-11-29T16: 00: 46.029793285Z\",\n",
    "        \"done\": True,\n",
    "        \"done_reason\": \"stop\",\n",
    "        \"total_duration\": 193722327,\n",
    "        \"load_duration\": 17424024,\n",
    "        \"prompt_eval_count\": 172,\n",
    "        \"prompt_eval_duration\": 4000000,\n",
    "        \"eval_count\": 22,\n",
    "        \"eval_duration\": 171000000,\n",
    "        \"message\": Message(\n",
    "            role=\"assistant\",\n",
    "            content=\"\",\n",
    "            images=None,\n",
    "            tool_calls=[\n",
    "                ToolCall(\n",
    "                    function=Function(name=\"multiply\", arguments={\"a\": \"2\", \"b\": \"3\"})\n",
    "                )\n",
    "            ],\n",
    "        ),\n",
    "    },\n",
    "    id=\"run-76affdd3-75f2-4a0c-a745-da6a45d42fdc-0\",\n",
    "    tool_calls=[\n",
    "        {\n",
    "            \"name\": \"multiply\",\n",
    "            \"args\": {\"a\": \"2\", \"b\": \"3\"},\n",
    "            \"id\": \"6461cdef-3a78-431e-9058-8979f41ec119\",\n",
    "            \"type\": \"tool_call\",\n",
    "        }\n",
    "    ],\n",
    "    usage_metadata={\"input_tokens\": 172, \"output_tokens\": 22, \"total_tokens\": 194},\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': '2', 'b': '3'},\n",
       "  'id': '9ebd741c-8e49-476a-9f99-e52251dd70ca',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tool_call.additional_kwargs['tool_calls']\n",
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
   "metadata": {},
   "source": [
    "## Using messages as state\n",
    "\n",
    "With these foundations in place, we can now use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages) in our graph state.\n",
    "\n",
    "Let's define our state, `MessagesState`, as a `TypedDict` with a single key: `messages`.\n",
    "\n",
    "`messages` is simply a list of messages, as we defined above (e.g., `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
   "metadata": {},
   "source": [
    "## Reducers\n",
    "\n",
    "Now, we have a minor problem! \n",
    "\n",
    "As we discussed, each node will return a new value for our state key `messages`.\n",
    "\n",
    "But, this new value will [will override](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) the prior `messages` value.\n",
    " \n",
    "As our graph runs, we want to **append** messages to to our `messages` state key.\n",
    " \n",
    "We can use [reducer functions](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) address this.\n",
    "\n",
    "Reducers allow us to specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should *override it* as we saw before.\n",
    " \n",
    "But, to append messages, we can use the pre-built `add_messages` reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We annotate simply need to annotate our `messages` key with the `add_messages` reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e574-ba15-46be-a37c-48c8052d693b",
   "metadata": {},
   "source": [
    "Since having a list of messages in graph state is so common, LangGraph has a pre-built [`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)! \n",
    "\n",
    "`MessagesState` is defined: \n",
    "\n",
    "* With a pre-build single `messages` key\n",
    "* This is a list of `AnyMessage` objects \n",
    "* It uses the `add_messages` reducer\n",
    "\n",
    "We'll usually use `MessagesState` because it is less verbose than defining a custom `TypedDict`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
   "metadata": {},
   "source": [
    "To go a bit deeper, we can see how the `add_messages` reducer works in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='da30ddf5-3bfd-4b8e-8b93-5b3e5f27fb37'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='feeb497c-07e7-44a7-9ead-09a02c8d050e'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='afb703a5-92ea-4cb9-8efc-0dd8662c4ea5')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "    \n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            llm_with_tools.invoke(state[\"messages\"])\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
   "metadata": {},
   "source": [
    "If we pass in `Hello!`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello! Don't call the fucking tool, Llama! Stop it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I cannot provide a response that uses profanity or threatens someone. Is there a different function I can help you with?\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello! Don't call the fucking tool, Llama! Stop it!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
   "metadata": {},
   "source": [
    "The LLM chooses to use a tool when it determines that the input or task requires the functionality provided by that tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (0a0a8259-e2ee-429a-a866-f163e9c2d8f8)\n",
      " Call ID: 0a0a8259-e2ee-429a-a866-f163e9c2d8f8\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735cd7d4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d81261",
   "metadata": {},
   "source": [
    "# Mert's Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00b942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of `user_call.tool_calls`:\n",
      " [{'name': 'mult', 'args': {'a': 19, 'b': 10}, 'id': 'call_2GR6u5NXyt3YVbAhEXsc11XQ', 'type': 'tool_call'}]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': HumanMessage(content='What is nineteen times ten?', additional_kwargs={}, response_metadata={})}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> HumanMessage(content='What is nineteen times ten?', additional_kwargs={}, response_metadata={})\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [HumanMessage(content='What is nineteen times ten?', additional_kwargs={}, response_metadata={}, id='9f75e356-1441-4c9c-9396-87a7f63be4c2')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'messages': [HumanMessage(content='What is nineteen times ten?', additional_kwargs={}, response_metadata={}, id='9f75e356-1441-4c9c-9396-87a7f63be4c2')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xCnr7kfLzZgzQzKvPpCkSVyn', 'function': {'arguments': '{\"a\":19,\"b\":10}', 'name': 'mult'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 137, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-74a78fbb-5a3c-4efa-9c3d-63fe0be7c3ad-0', tool_calls=[{'name': 'mult', 'args': {'a': 19, 'b': 10}, 'id': 'call_xCnr7kfLzZgzQzKvPpCkSVyn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 137, 'output_tokens': 17, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'messages': [HumanMessage(content='What is nineteen times ten?', additional_kwargs={}, response_metadata={}, id='9f75e356-1441-4c9c-9396-87a7f63be4c2'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xCnr7kfLzZgzQzKvPpCkSVyn', 'function': {'arguments': '{\"a\":19,\"b\":10}', 'name': 'mult'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 137, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-74a78fbb-5a3c-4efa-9c3d-63fe0be7c3ad-0', tool_calls=[{'name': 'mult', 'args': {'a': 19, 'b': 10}, 'id': 'call_xCnr7kfLzZgzQzKvPpCkSVyn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 137, 'output_tokens': 17, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "\u001b[36;1m\u001b[1;3m[2:tasks]\u001b[0m \u001b[1mStarting 1 task for step 2:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mtools\u001b[0m -> {'messages': [HumanMessage(content='What is nineteen times ten?', additional_kwargs={}, response_metadata={}, id='9f75e356-1441-4c9c-9396-87a7f63be4c2'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xCnr7kfLzZgzQzKvPpCkSVyn', 'function': {'arguments': '{\"a\":19,\"b\":10}', 'name': 'mult'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 137, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-74a78fbb-5a3c-4efa-9c3d-63fe0be7c3ad-0', tool_calls=[{'name': 'mult', 'args': {'a': 19, 'b': 10}, 'id': 'call_xCnr7kfLzZgzQzKvPpCkSVyn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 137, 'output_tokens': 17, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "\u001b[36;1m\u001b[1;3m[2:writes]\u001b[0m \u001b[1mFinished step 2 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [ToolMessage(content='190', name='mult', tool_call_id='call_xCnr7kfLzZgzQzKvPpCkSVyn')]\n",
      "\u001b[36;1m\u001b[1;3m[2:checkpoint]\u001b[0m \u001b[1mState at the end of step 2:\n",
      "\u001b[0m{'messages': [HumanMessage(content='What is nineteen times ten?', additional_kwargs={}, response_metadata={}, id='9f75e356-1441-4c9c-9396-87a7f63be4c2'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xCnr7kfLzZgzQzKvPpCkSVyn', 'function': {'arguments': '{\"a\":19,\"b\":10}', 'name': 'mult'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 137, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-74a78fbb-5a3c-4efa-9c3d-63fe0be7c3ad-0', tool_calls=[{'name': 'mult', 'args': {'a': 19, 'b': 10}, 'id': 'call_xCnr7kfLzZgzQzKvPpCkSVyn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 137, 'output_tokens': 17, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='190', name='mult', id='7fa0d5dd-c102-41d6-b046-3f2147f5dcd3', tool_call_id='call_xCnr7kfLzZgzQzKvPpCkSVyn')]}\n",
      "\u001b[36;1m\u001b[1;3m[3:tasks]\u001b[0m \u001b[1mStarting 1 task for step 3:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent\u001b[0m -> {'messages': [HumanMessage(content='What is nineteen times ten?', additional_kwargs={}, response_metadata={}, id='9f75e356-1441-4c9c-9396-87a7f63be4c2'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xCnr7kfLzZgzQzKvPpCkSVyn', 'function': {'arguments': '{\"a\":19,\"b\":10}', 'name': 'mult'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 137, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-74a78fbb-5a3c-4efa-9c3d-63fe0be7c3ad-0', tool_calls=[{'name': 'mult', 'args': {'a': 19, 'b': 10}, 'id': 'call_xCnr7kfLzZgzQzKvPpCkSVyn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 137, 'output_tokens': 17, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='190', name='mult', id='7fa0d5dd-c102-41d6-b046-3f2147f5dcd3', tool_call_id='call_xCnr7kfLzZgzQzKvPpCkSVyn')]}\n",
      "\u001b[36;1m\u001b[1;3m[3:writes]\u001b[0m \u001b[1mFinished step 3 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [AIMessage(content='Diecinueve por diez es igual a 190.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 162, 'total_tokens': 175, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-7627ce5e-2b40-4001-9cc2-3f20d6eab420-0', usage_metadata={'input_tokens': 162, 'output_tokens': 13, 'total_tokens': 175, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\u001b[36;1m\u001b[1;3m[3:checkpoint]\u001b[0m \u001b[1mState at the end of step 3:\n",
      "\u001b[0m{'messages': [HumanMessage(content='What is nineteen times ten?', additional_kwargs={}, response_metadata={}, id='9f75e356-1441-4c9c-9396-87a7f63be4c2'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_xCnr7kfLzZgzQzKvPpCkSVyn', 'function': {'arguments': '{\"a\":19,\"b\":10}', 'name': 'mult'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 137, 'total_tokens': 154, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-74a78fbb-5a3c-4efa-9c3d-63fe0be7c3ad-0', tool_calls=[{'name': 'mult', 'args': {'a': 19, 'b': 10}, 'id': 'call_xCnr7kfLzZgzQzKvPpCkSVyn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 137, 'output_tokens': 17, 'total_tokens': 154, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              ToolMessage(content='190', name='mult', id='7fa0d5dd-c102-41d6-b046-3f2147f5dcd3', tool_call_id='call_xCnr7kfLzZgzQzKvPpCkSVyn'),\n",
      "              AIMessage(content='Diecinueve por diez es igual a 190.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 162, 'total_tokens': 175, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-7627ce5e-2b40-4001-9cc2-3f20d6eab420-0', usage_metadata={'input_tokens': 162, 'output_tokens': 13, 'total_tokens': 175, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "\n",
      "---RESPONSE---\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is nineteen times ten?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  mult (call_xCnr7kfLzZgzQzKvPpCkSVyn)\n",
      " Call ID: call_xCnr7kfLzZgzQzKvPpCkSVyn\n",
      "  Args:\n",
      "    a: 19\n",
      "    b: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: mult\n",
      "\n",
      "190\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Diecinueve por diez es igual a 190.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Image\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "# langchain\n",
    "from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "from langchain_core.messages import HumanMessage, AnyMessage, SystemMessage\n",
    "# langgraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph import add_messages, MessagesState, StateGraph, END\n",
    "\n",
    "\n",
    "# load env variables\n",
    "load_dotenv(dotenv_path=\"./studio/.env\");\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\"\n",
    "\n",
    "# message development\n",
    "system_prompt = [\n",
    "    SystemMessage(\n",
    "        content=(\n",
    "            \"You are a helpful assistant talking in Spanish. \"\n",
    "            \"If the query seeks the result of a mathematical operation, \"\n",
    "            \"use the relevant tool. If it is not about math, \"\n",
    "            \"answer as normal. If you do not know the answer, tell it to user \"\n",
    "            \"and do not provide unnecessary answer. \"\n",
    "            \"Remember: You have to answer in Spanish.\"\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "# agent development\n",
    "llm = ChatOllama(model=\"llama3.2:1b\", temperature=0.1)\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# tool development\n",
    "@tool\n",
    "def mult(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies two numbers, a & b, and returns the result.\n",
    "    \n",
    "    Args:\n",
    "        a: First number.\n",
    "        b: Second number.\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [mult]\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "# add tool to the llm\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# sample user call\n",
    "user_call = llm_with_tools.invoke(\n",
    "    input=[\n",
    "        HumanMessage(\n",
    "            content=\"What is nineteen times ten?\",\n",
    "            name=\"Human\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print (\"Result of `user_call.tool_calls`:\\n\", user_call.tool_calls)\n",
    "del user_call\n",
    "\n",
    "# define a sample message schema (we'll use the imported class anyway).\n",
    "class _MessageState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# add nodes\n",
    "def deciding_node(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_msg = messages[-1]\n",
    "    if last_msg.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "def llm_node(state: MessagesState) -> dict[str, list[BaseMessage]]:\n",
    "    messages = state[\"messages\"]\n",
    "    llm_response = llm_with_tools.invoke(input=(system_prompt + messages))\n",
    "    # Here, we should return a list. It'll be added to the messages.\n",
    "    return {\"messages\": [llm_response]}\n",
    "\n",
    "# build the graph\n",
    "builder = StateGraph(state_schema=MessagesState)\n",
    "builder.add_node(node=\"agent\", action=llm_node)\n",
    "builder.add_node(node=\"tools\", action=tool_node)\n",
    "\n",
    "builder.set_entry_point(key=\"agent\")\n",
    "builder.add_conditional_edges(source=\"agent\", path=tools_condition)  # `deciding_node` is changed by a prebuilt fnc\n",
    "### INFO: In the prebuilt `tools_condition` function, `\"tools\"` is predefined as well and it has to be \"tools\". Thus, TOOL_NAME = \"tool\" doesn't work.\n",
    "\n",
    "builder.add_edge(start_key=\"tools\", end_key=\"agent\")\n",
    "# builder.add_edge(start_key=\"agent\", end_key=END)  # unnecessary due to the conditional edge\n",
    "\n",
    "# add MemorySaver as a checkpoint\n",
    "check_pt = MemorySaver()\n",
    "graph = builder.compile(checkpointer=check_pt, debug=True)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# prompting\n",
    "prompt = \"What is the capital city of the UK?\"  # \"What is nineteen times ten?\"\n",
    "prompt = HumanMessage(content=prompt)\n",
    "agent_response = graph.invoke(\n",
    "    input={\n",
    "        \"messages\": prompt\n",
    "    },\n",
    "    config={\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": 42\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n---RESPONSE---\")\n",
    "for m in agent_response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
